<pre class='metadata'>
Title: Everyone Deserves a Little Order
Status: P
Audience: LEWG, LWG
Editor: Gašper Ažman <gasper.azman@gmail.com>
Editor: Jeff Snyder <jeff-isocpp@caffeinated.me.uk>
Shortname: P0891
Abstract: The specification of ordering algorithms at the end of [[P0768R1]] does not provide the ability to provide a default order for user-defined types (since they are specified in such a way that they are not intended to be customization points), and yet mixes in such a customization for iec559 floating point types. This paper suggests providing the functionality of both in a composable and principled way.
Group: WG21
Date: 2019-01-20
Markup Shorthands: markdown yes
Revision: 2
ED: https://github.com/atomgalaxy/a-little-order/strong-ordering.bs
</pre>

<style>
.ins, ins, ins *, span.ins, span.ins * {
  background-color: rgb(200, 250, 200);
  color: rgb(0, 136, 0);
  text-decoration: none;
}

.del, del, del *, span.del, span.del * {
  background-color: rgb(250, 200, 200);
  color: rgb(255, 0, 0);
  text-decoration: line-through;
  text-decoration-color: rgb(255, 0, 0);
}
</style>

Revision History {#history}
===========================

R1: Incorporated feedback from LEWG meeting in Rappersville. {#rap-feedback}
----------------------------------------------------------------------------

The feedback was:
- Remove the floating point exception (bullet 1.1) as R0 recommended, since Unicode strings, etc., are a possible rationale.
- Do not propose propose making existing `*_order` functions "customization points" (as used in [[!P0551R3]]).
- Add a new `default_order` customization point, along with a bikeshedding section on its actual name, with the behaviour:
    - It has the IEC 559 behavior from bullet 1.1 of `strong_order`
    - It is defined for all (other) floating-point types; it is implementation-defined whether it is consistent with the partial order from the comparison operators. (Implementations should do this.)
    - It is a customization point (à la [[!P0551R3]]).
- Investigate the possibility of adding Lawrence's weak order (from [[P0100R2]]) for floating-point numbers (which did not make it in with spaceship).


R2: Incorporated feedback from LEWG meeting in San Diego, merged with [[P0863R1]] {#sd-feedback}
------------------------------------------------------------------------------------------------

Feedback in San Diego was:

- We want to solve `std::set<T>` for not obviously comparable `T` (0/6/4/1/1).
- We want to solve `std::unordered_set<T>` for not obviously hasheable `T`. (Out of scope of this paper)
- We need to adress the fact that containers need to provide specializations of `strong_order` if it is a customization point.
- We want `strong_order` to be the customization point (Herb's proposed poll) - never taken.


Status of this paper {#sup}
===========================

R2 of this paper is a merge of its R1 and Jeff Snyder's [[P0873R1]], and is synchronized with Barry Revzin's [[D1186R1]]. It incorporates all feedback for R0 and R1, and presents a coherent design for the library components of `<=>`.


Problem Description {#problem}
==============================

This paper is a proposal to amend the *comparison algorithms* that have been voted into the working draft as part of [[P0768R1]].

As worded, the `strong_order` comparison algorithm provides:

- a strong ordering for some types that do not have it provided by `<=>` (iec559 floating point types),
- a way of generating a value of type `strong_ordering` by falling back to the `==` and `<` operators if `<=>` is not callable or does not result in a `strong_ordering`.

However, the authors of this paper and the author of [[P0515R3]] intended for `strong_order` to be a customization point, and it is not currently usable as such.

In the standard, we need to provide the ability to customize `strong_order` and a way to fall back to `==` and `<`. This paper argues that these are fundamentally incompatible, and cannot be served by the same function.

[[P0891R0]] and [[P0891R1]] of this paper presented the case for having a customization point for ordering in the language. This paper only summarizes the currently relevant bits of that discussion. For wider context, the reader should refer to the previous revisions, as well as to [[P0863R1]].


Principles {#principles}
========================

To arrive at the final design of this paper, we used the following principles:

- <dfn>consistency</dfn>: `*_order` algorithms should behave consistently with `<=>` by default.
- <dfn>weakening</dfn>: If a type has a given order, than it also has all weaker orders.
- <dfn>ambiguity of legacy</dfn>: The ordering category provided by the legacy comparison operators is ambiguous. The standard currently expects merely that `<` provides a weak ordering.
- <dfn>customization</dfn>: As `<=>` is a customization point for the natural ordering on a type, so `strong_order` is a customization point for an arbitrary strong order on that type.
- <dfn>fallback</dfn>: We need convenient functions to get `*_ordering` types from legacy comparison operators.


From these principles, these corollaries follow:

- <dfn>Corollary 1</dfn>: from [=consistency=] it follows that, if `<=>` provides a given order `X`, then the default implementation of `X_order` should use it.
- <dfn>Corollary 2</dfn>: from [=consistency=], [=weakening=] and [=customization=], it follows that:
    - if `<=>` does not provide a strong enough order, but a stronger ordering function (e.g. `strong_order` for `weak_order`, `weak_order` for `partial_order`) is available, then the weaker ordering function must fall back on it (this works recursively, so if `strong_order` is defined, so is `partial_order`).
- <dfn>Corollary 3</dfn>: from [=consistency=] and [=fallback=], it follows that if `<=>` exists, the fallback function should use it in preference of legacy comparison operators.
- <dfn>Corollary 4</dfn>: From [=fallback=] and [=ambiguity of legacy=], it follows that by using a fallback function, the user is asserting that `<` and `==` implement the corresponding ordering.
- <dfn>Corollary 5</dfn>: From [=customization=] and the definition of *customization point*, it follows that `*_order` functions must be specified as <i>does not participate in overload resolution</i> when they cannot be synthesized according to the above rules.
- <dfn>Corollary 6</dfn>: From [=Corollary 4=] and [=Corollary 5=] it follows that the fallbacks and the customization points cannot be the same functions, as their roles are fundamentally incompatible. To illustrate: the fallback function for synthesizing `strong_ordering` must exist whenever `<` and `==` do, but the `strong_order` customization point must not be synthesized purely from those.


In addition, we have made the following observations:

- Given [[D1185R1]] provides a method of generating a `<=>` operator from `<` and `==`, we should (due to [=consistency=]) defer to that method for synthesizing the fallback functions.
- If `strong_order` is a customization point for providing a stronger order than `<=>` does, data structures that recurse to their contents for `<=>` should also recurse for `strong_order`.
- Given that the '<=>' operator is not being provided for any of the types in the standard library C++20, we are deferring proposing this until such time as `<=>` is proposed for them as well.

Questions for LEWG: {#lewg-questions}
=====================================

1. <dfn>Question: consensus</dfn>: Is there consensus that the [=customization=] premise (as above) is correct and should be adopted?
    - If not, then should the iec559 exception bullet in the current working draft be removed?
2. <dfn>Question: fallbacks</dfn>:Is there consensus that the [=fallback=] premise (as above) is correct and should be adopted?
    - Rejecting this means that we are rejecting the rationale for their inclusion in the current working draft and that they should be removed.

(The [=consistency=], [=weakening=] and [=ambiguity of legacy=] are true from a good design, mathematical, and empirical point of view, respectively, so they are not subject to poll).

If the answers to both of those questions are yes, then this paper follows in its entirety.


Discussion {#discussion}
========================

Discussion of [=Question: consensus=] {#discussion-poll-1}
----------------------------------------------------------

  The arguments around whether `strong_order` should be a customization point have centered around the following issues. We summarize the discussion below.

  - Is it even useful?
  - Given that it is viral, is it worth the implementation effort?
  - Should all of them be customization points?
  - How can I teach this?


### Is it useful ### {#but-is-it-legal-ill-make-it-legal}

  It's useful enough that SG6 pushed for the iec559 exception until they got it. The issue is that any time one would want to put an iec559 exception into a container, say, optional or a tuple, they would have to define `strong_order` for it. The current wording disallows that completely, however. The current wording is not composable. As an example, it is impossible to define `strong_order` for `complex<float>` as, for instance, a lexicographic ordering, with current wording, even though that's what it should be for speed. There should not be a `<` that works on complex, though.

  It's useful for any type that provides a less-than-strong `<=>` that wants to enable its users to use `std::unique` on it (they don't care about the order, they only care about `==`, but the function that establishes  the precondition to `unique`, `sort`, *does* care about an order that's compatible with `==`, which is `strong_order`, and by premise, not `<=>`. Same goes for putting it in a `std::set` or `std::map` where defining `std::hash` is not an obvious exercise and consequently the unordered containers are not an option.

It's useful enough for *Stepanov* and *Mc Jones* to include it in *Regular* in <i>Elements of Programming</i>.

Tony van Eerd: "Every place I go the first thing I write is sorted vector."

This is a short list of the most obvious algorithms that require any order to work:
- unique (via sort)
- set/map


### Given that it is viral, is it worth the implementation effort? ### {#impl-effort}

Given that any customization point we designate has to potentially be overloaded for all the generic wrappers in the standard library, is it even worth the effort defining them?

This paper does not propose any such wrappers, because the standard library doesn't even have `<=>` yet, but the authors only mean to propose `strong_order` be implemented, as that is the only one they've ever needed.


### How can I teach this? ### {#faq-teaching}

For types that endeavour to be *Regular* or something like it (as in, have sane value semantics), do the following.


#### Writing new types: #### {#wrinting-new}
- `operator==` defines what "strong equality" means. This is because copies must compare equal, and `==` should be the finest relation that observes this rule.
- if `(x <=> y) == 0` if and only if `x == y`, then `operator<=>` should return `strong_ordering`, otherwise it should return `weak_ordering` (unless it only defines a partial order, but then you're not asking the question).
- If your type does not provide an order, you should still provide an overload of `strong_order`.
- If you are obeying the rule of zero, writing `auto operator<=>(...) = default` will give you the correct `==` and `<=>` without any additional work. In most cases, this should already be enough, since `<=>` will result in a `strong_ordering`.
- if writing a generic wrapper, or your constituent types have an overloaded `strong_order`, you must then also define `strong_order` to be:

```
strong_ordering strong_order(T x, T y) {
  return strong_order(tie(x.m1, x.m2, ...), tie(y.m1, y.m2, ...));
}
```
or, hopefully, when we get reflection, be able to generate it.


#### Using orderings: #### {#using-orderings}
Generic algorithms in general should require and call `weak_order(x, y)`. It will either use the default (weak) ordering on `<=>`, so there are no surprises, or fall back on `strong_order`, which will call `<=>` if it is strong, so no suprises, and if `<=>` does not exist, the type will hopefully have an overload for `strong_order` specifically, which is, again, no surprises. It always does the right thing.

Data structures that require a weak order should default to it as well.


Discussion of [=Question: fallbacks=] {#discussion-fallbacks}
-------------------------------------------------------------

The arguments on whether we need to provide the fallback functions for legacy types center around:

- How do we make it easy is it to define `<=>` in terms of `<` and `==` of a legacy type?

[[D1186R1]] makes that trivial, without any fallbacks needed. In fact, fallbacks must be defined in terms of the `3WAY(X, Y)` expression it introduces.


- How do we work with types that may or may not define `<=>` in generic contexts, but we know we have the requisite preconditions on `<` and `==`? {#generic-contexts}

The authors can't think of a generic context where those assumptions hold reliably. `3WAY(X, Y)` and the fallbacks defined with it are useful in this scenario. However, the authors can't really think of an actual scenario where you are both in a generic context and you know the preconditions on all the possible types you might want to use there.


- In a context where we need to pass an ordering type as a parameter to a function, but we need to obtain it from a legacy type, how do we do that?

The `3WAY(X, Y)`-derived fallback functions do that too.


Basically, we need fallbacks for the reasons listed above. However, one should remember:
- in generic contexts, we usually do not know the preconditions. We should use the `weak_order` customization point.


Status Quo {#status}
====================

For reference, the current specification for the `std::strong_order` algorithm is as follows:

```cpp
template<class T>
constexpr strong_ordering strong_order(const T& a, const T& b);
```

1. Effects: Compares two values and produces a result of type `strong_ordering`:
    1. If `numeric_limits<T>::is_iec559` is true, returns a result of type `strong_ordering` that is consistent with the `totalOrder` operation as specified in ISO/IEC/IEEE 60559.
    2. Otherwise, returns `a <=> b` if that expression is well-formed and convertible to `strong_ordering`.
    3. Otherwise, if the expression `a <=> b` is well-formed, then the function shall be defined as deleted.
    4. Otherwise, if the expressions `a == b` and `a < b` are each well-formed and convertible to `bool`, returns `strong_ordering::equal` when `a == b` is `true`, otherwise returns `strong_ordering::less` when `a < b` is `true`, and otherwise returns `strong_ordering::greater`.
    5. Otherwise, the function shall be defined as deleted.


Proposal {#proposal}
====================

Make `strong_order` and friends customization points {#propose-customization}
-----------------------------------------------------------------------------

For the functions `strong_order`, `weak_order`, `partial_order`,
`strong_equal` and `weak_equal`, we propose to:

- Remove the fallbacks to `==` and `<`
- Have the functions not participate in overload resolution (instead of being defined as deleted) if there is no strong order available.

Remove the `strong_equal` and `weak_equal` comparison algorithms {#remove-equal}
--------------------------------------------------------------------------------


If we accept [[P1185R0]]'s rationale for not calling `<=>` when the user only
needs equality (as EWG did in San Diego), we should also avoid doing so in the
library. However, without making assumptions about the behaviour of `==`, there
is no way to implement `strong_equal` and `weak_equal` without calling `<=>`.

Therefore, we propose removing the `strong_equal` and `weak_equal`
customisation points.


Replace the iec559 rule in `strong_order` with separate overloads {#propose-iec559}
-----------------------------------------------------------------------------------

Since `strong_order` as a customiation point, the strong order for floating
point types should be provided as overloads of `strong_order` rather than being
baked into the generic `strong_order` function.

We propose that the bullet point regarding `iec559` be removed from the
`strong_order` algorithm, and that the following three overloads for
`strong_order` are added:

- `strong_order(float, float);` 
- `strong_order(double, double);` 
- `strong_order(long double, long double);` 

These overloads should implement the `totalOrder` operation as specified in
ISO/IEC/IEEE 60559, and should not participate in overload resolution if
`numeric_limts<T>::is_iec559` is false for the type of their arguments.

Make the weaker customization points call stronger customizatoin points {#propose-weakening}
--------------------------------------------------------------------------------------------

To handle cases such as where a type provides a `partial_ordering` from `<=>`
and a `strong_order` overload, if a customization point cannot get an
appropriate result from calling `<=>`, it should try to call a customization
point for an order stronger than its own. Specifically:

- `weak_order` should fall back to calling `strong_order`
- `partial_order` should fall back to calling `weak_order`

Add fallback functions {#proposal-fallback}
-------------------------------------------

To avoid losing the functionality of the existing comparison algorithms, we
propose to keep them under new names, with the following changes to their
behaviour:

- They will, in preference to anything else, return the
    result of calling the corresponding customization point.
- They will not attempt to call `<=>` directly, as this is called by the
    customisation point.
- They will fall back to `==` and `<` using the language mechanism proposed by
    [[!D1186R1]] instead of calling `==` and `<` directly.

As per the original comparison algorithms, they will be defined as deleted if
neither the corresponding customization point nor the `==` and `<` operators
are available.

Following the same reasoning as in [[#remove-equal]], there will be no fallback
functions for `strong_equality` and `weak_equality`.

We propose naming the fallback functions `strong_order_assume`, `weak_order_assume` and `partial_order_assume`.

Other options to consider:
 - `X_order_assume`
 - `assume_X_order`
 - `fallback_X_order`
 - `X_order_fallback`

On Compatibility Between the Natural and Default Orderings {#compat}
====================================================================

*Elements of Programming* specifies that for types where the natural and default orderings differ, the default ordering should be *finer* than the natural one: that is, if `a` and `b` are *comparable* and compare unequal under `<=>`, the default order produces the same result (less or greater).

It is the opinion of the author that requiring this in the language of the standard library as a mandatory semantic constraint seems like a bad idea.

For instance, if one takes the Gaussian integers ordered by the Manhattan distance to zero (sum of absolute values of the two components), the compatible total order (a lexicographic ordering of every equivalence class) is far slower to compute than the simple lexicographic one.

Furthermore, if needed, a *finer* compatible total order can always be achieved on the fly by comparing with the natural order first: if the result is `less` or `greater`, keep the result; otherwise, fall back on the default ordering.


Why not just make `strong_order` a customization point? {#why-not}
==================================================================

Main reasons:
    1. it would inhibit providing both a natural (`<=>`, `strong_order`) (and possibly slow) and a default (fast) order for a type
    2. the committee guidance strongly preferred this option, as it keeps the meaning of `strong_order` fixed (since it is not a customization point)
    3. it is less surprising if the order algorithms that are related to order types by name (`weak_order` - `weak_ordering`, `partial_order` - `partial_ordering`, `strong_order` - `strong_ordering`) had the same specification, while a fourth customization point that isn't related by any of them by name serves as the customization point for default order.

It is notable that this was the direction suggested by the orginal paper, but the committee rejected it.


Proposed Wording {#wording}
===========================

From section 24.x.4, Comparison Algorithms [cmp.alg], under `strong_order`:
<div class='del'>
    (1.1)  If `numeric_limits<T>::is_iec559` is true, returns a result of type `strong_ordering`
that is consistent with the `totalOrder` operation as specified in ISO/IEC/IEEE 60559.

    (1.2) Otherwise, returns
</div>

<div class='ins'>
    (1.2) Returns

</div>

After 24.x.4 paragraph 3, `weak_order`, add:

<div class='ins'>
<ul style='list-style-type: none; padding-left: 0px;'>
<li>`template<class T> constexpr strong_ordering default_order(const T& a, const T& b);`<br/>4. *Effects:*
<ul style='list-style-type: none'>
<li>(4.1) if `std::numeric_limits<T>::is_iec559` is true, returns a result of type `strong_ordering` that is consistent with the `totalOrder` operation as specified in ISO/IEC/IEEE 60559.</li>
<li>(4.2) Otherwise, returns `strong_order(a, b)` if that expression is well-formed and convertible to `strong_ordering`</li>
<li>(4.3) Otherwise, this function shall not participate in overload resolution.</li>
</ul>
</li>
<li>5. *Remarks*: this function is a designated customization point ([namespace.std]).</li>
</ul>

</div>

Under `[cmp.syn]` -> `[cmp.alg]`, insert declaration:
<div class='ins'>
`template <class T> constexpr strong_ordering default_order(const T& a, const T& b);`

</div>


Acknowledgments {#ack}
======================

I would like to thank
  - **Roger Orr** for bringing this to my attention;
  - **Thomas Köppe** for his valuable comments, review, and most of all some extremely clear and laconic wording;
  - **Sam Finch** for *thoroughly* breaking my examples, some example code, great substantive comments, and pointing out that the current definition actually breaks types that define a partially-ordered set of comparison operators;
  - **Richard Smith** for further fixing my example in light of Concepts, and example code.
  - **Herb Sutter and Walter Brown** for providing guidance on customization points.
  - **Louis Dionne** for great comments on the structure of the paper and how to bring the focus where it needs to be;
  - **Walter Brown** for representing the paper at committee meetings when I could not make it in person, and guidance with direction;
  - **Herb Sutter** for his comments and support for getting ordering right.

And, *again*, a special thank-you to Walter Brown, who, with his final lightning talk in Bellevue, reminded me to remember whose shoulders I'm standing on.

Thank you all!


Appendix A: Proof `strong_order` is not a valid customization point {#example-cust-point}
=========================================================================================

Say we have a template struct representing the Gaussian integers, with a *natural order* defined by the Manhattan distance from `0+0i`. This struct still defines a `std::strong_order` to model **Regular**.

Note: The **Regular** above refers to the *Elements of Programming* concept, not the ISO C++ **Regular**, which is weaker.

Note: There is no natural order on Gaussian integers, but humor this example, please.

```cpp
namespace user {
  template <typename T>
  struct gaussian {
    static_assert(std::is_integral_v<T>);
    T re;
    T im;

    constexpr std::strong_equality operator==(gassian const& other) const {
      return re == other.re && im == other.im;
    }
    constexpr std::weak_ordering operator<=>(gaussian const& other) const {
      return (*this == other) ? std::weak_ordering::equal
                              : (abs(*this) == abs(other)) ? std::weak_ordering::equivalent
                                                           : abs(*this) <=> abs(other);
    }
    friend constexpr T abs(gaussian const&) {
      using std::abs;
      return abs(re) + abs(im);
    }

    friend constexpr std::strong_ordering strong_order(gaussian const& x,
                                                       gaussian const& y) {
      // compare lexicographically
      return std::tie(x.re, x.im) <=> std::tie(y.re, y.im);
    }
  };
}
```

Consider a transparent ordering operator for `map`:
```cpp
struct strong_less
  template <typename T, typename U>
  bool operator()(T const& x, U const& y) {
    using std::strong_order;  // use ADL
    return strong_order(x, y) < 0;
  }
  using is_transparent = std::true_type;
};
```

Also say we had a type with an implicit conversion to our `gaussian`:
```cpp
template <typename T>
struct lazy {
  std::function<T()> make;
  operator T() const { return make(); }
};
```

This function now fails to compile, because the chosen `std::strong_order` is deleted.
```cpp
bool exists(lazy<gaussian<int>> const& x,
            std::set<gaussian<int>, strong_less> const& in) {
  /* imagine this being a template in both parameters - it's pretty normal */
  return in.count(x);
}
```

The std-provided `std::strong_order` is deleted because it cannot be synthesized from `gaussian`'s `operator<=>`. The reason it is chosen over the friend function, however, is because the standard template matches better than the friend which would require an implicit conversion.

If the std-provided `std::strong_order` did not participate in overload resolution, however, this example would work just fine.


<!--
 vim: ft=markdown wrap linebreak nolist textwidth=0 wrapmargin=0
-->
